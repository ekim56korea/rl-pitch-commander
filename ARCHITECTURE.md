
### 2. `ARCHITECTURE.md`
**ì—­í• :** ì‹œìŠ¤í…œ ì„¤ê³„ë„. ë°ì´í„°ì˜ íë¦„ê³¼ ê° ëª¨ë“ˆ(í™˜ê²½, ì—ì´ì „íŠ¸, ëª¨ë¸)ì˜ ìƒí˜¸ì‘ìš©ì„ ê¸°ìˆ ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

# ğŸ—ï¸ System Architecture

ë³¸ ë¬¸ì„œëŠ” `rl-pitch-commander`ì˜ ê¸°ìˆ ì  ì•„í‚¤í…ì²˜ì™€ ë°ì´í„° íŒŒì´í”„ë¼ì¸, ê·¸ë¦¬ê³  ëª¨ë“ˆ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## 1. High-Level Architecture Diagram
ì‹œìŠ¤í…œì€ í¬ê²Œ **Data Layer**, **Simulation Environment (Digital Twin)**, **Agent Core**, **Application Layer**ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

```mermaid
graph TD
    subgraph "Data Layer (DuckDB)"
        Raw[Savant Raw Data] --> |dbt| Feat[Feature Store<br/>(VAA, RunValue, History)]
    end

    subgraph "Simulation Environment (Gymnasium)"
        Feat --> Physics[Physics Engine]
        Feat --> Batter[Batter Behavior Model<br/>(XGBoost/Transformer)]
        Feat --> Umpire[Umpire Model<br/>(Probabilistic Zone)]
        Physics & Batter & Umpire --> State[State Generator]
        State --> Reward[Reward Calculator]
    end

    subgraph "Agent Core (RL)"
        State --> Policy[Policy Network<br/>(Actor-Critic / LSTM)]
        Policy --> Action[Action Selection<br/>(Pitch Type, Location)]
        Action --> Physics
        Reward --> Policy
    end

    subgraph "Application Layer"
        Policy --> API[Inference API<br/>(FastAPI)]
        API --> UI[Analyst Dashboard<br/>(Streamlit/React)]
    end
2. Component Details
2.1 Data Lakehouse (DuckDB)

Storage: 2015-2025 MLB Pitch Data (savant.duckdb).

Feature Engineering: dbtë¥¼ ì‚¬ìš©í•˜ì—¬ plate_x, plate_z ë“±ì˜ ì¢Œí‘œ ë°ì´í„°ì™€ release_spin_rate ë“±ì„ ê²°í•©, íƒ€ìë³„ Hot/Cold Zone ë° Pitch Valueë¥¼ ì‚¬ì „ ê³„ì‚°.

Optimization: ì¸ë©”ëª¨ë¦¬ OLAP ì²˜ë¦¬ë¥¼ í†µí•´ í•™ìŠµ ì‹œ Replay Bufferë¡œì˜ ê³ ì† ë°ì´í„° ì „ì†¡ ì§€ì›.

2.2 The Digital Twin (Environment)

ì‹¤ì œ ê²½ê¸°ì™€ ë™ì¼í•œ ë³´ìƒê³¼ ìƒíƒœ ì „ì´ë¥¼ ì œê³µí•˜ëŠ” ê°€ìƒ í™˜ê²½ì…ë‹ˆë‹¤.

Batter Simulator:

ì…ë ¥: íˆ¬êµ¬ ì •ë³´(êµ¬ì¢…, êµ¬ì†, ìœ„ì¹˜, ë¬´ë¸Œë¨¼íŠ¸) + íƒ€ì ID + ì¹´ìš´íŠ¸.

ì¶œë ¥: Swing ì—¬ë¶€, Contact í’ˆì§ˆ(Exit Velocity, Launch Angle).

ëª¨ë¸: Gradient Boosting Machine (XGBoost) ê¸°ë°˜, íƒ€ìë³„ ê°œë³„ ëª¨ë¸ë§.

Physics Engine: ê³µê¸°ì—­í•™ì  í•­ë ¥(Drag)ê³¼ ë§ˆê·¸ëˆ„ìŠ¤ íš¨ê³¼ë¥¼ ê³ ë ¤í•˜ì—¬ ë¦´ë¦¬ìŠ¤ í¬ì¸íŠ¸ì—ì„œ í¬ìˆ˜ ë¯¸íŠ¸ê¹Œì§€ì˜ ê¶¤ì  ê³„ì‚°.

2.3 Agent Core (The Brain)

Algorithm: PPO (Proximal Policy Optimization) with LSTM Support.

Network: íˆ¬êµ¬ ì‹œí€€ìŠ¤(ì´ì „ ê³µë“¤ì˜ ì •ë³´)ë¥¼ ê¸°ì–µí•˜ê¸° ìœ„í•œ Recurrent Neural Network êµ¬ì¡° ì‚¬ìš©.

Initialization: Behavior Cloning(BC)ì„ í†µí•´ ì‹¤ì œ MLB ì—ì´ìŠ¤ íˆ¬ìˆ˜ë“¤ì˜ ì •ì±…ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµ(Pre-training) í›„ ê°•í™”í•™ìŠµ ì ìš©.

3. Infrastructure & MLOps
Containerization: ëª¨ë“  ëª¨ë“ˆì€ Dockerë¡œ ì»¨í…Œì´ë„ˆí™”ë˜ì–´ ì˜ì¡´ì„± ì¶©ëŒ ë°©ì§€.

Experiment Tracking: TensorBoard ë° MLflowë¥¼ ì‚¬ìš©í•˜ì—¬ Reward ê³¡ì„  ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì .


---