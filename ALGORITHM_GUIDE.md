```markdown
# ğŸ§  Algorithm & Math Guide

ë³¸ ë¬¸ì„œëŠ” íˆ¬êµ¬ ì „ëµ ìµœì í™”ë¥¼ ìœ„í•´ ì •ì˜ëœ **Markov Decision Process (MDP)**ì˜ ìˆ˜í•™ì  êµ¬ì¡°ì™€ ê°•í™”í•™ìŠµ ë°©ë²•ë¡ ì„ ìƒì„¸íˆ ê¸°ìˆ í•©ë‹ˆë‹¤.

## 1. Problem Formulation (MDP Definition)

ìš°ë¦¬ëŠ” íˆ¬êµ¬ ì‹œí€€ì‹± ë¬¸ì œë¥¼ **Episodic MDP**ë¡œ ì •ì˜í•©ë‹ˆë‹¤. í•œ íƒ€ì„(Plate Appearance)ì´ í•˜ë‚˜ì˜ ì—í”¼ì†Œë“œì…ë‹ˆë‹¤.

### 1.1 State Space ($S_t$)
íˆ¬ìˆ˜ê°€ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ê´€ì¸¡ ì •ë³´ì…ë‹ˆë‹¤. ì°¨ì› ì¶•ì†Œë¥¼ ìœ„í•´ í•µì‹¬ ë³€ìˆ˜ë§Œ ì„ ë³„í•©ë‹ˆë‹¤.

* **Game Context:** $C_{game} = \{ \text{Balls}, \text{Strikes}, \text{Outs}, \text{BaseRunners}, \text{ScoreDiff} \}$
* **Pitcher State:** $P_{state} = \{ \text{PitchCount}, \text{FatigueLevel}, \text{PrevPitchType}, \text{PrevPitchLoc} \}$
* **Batter Context:** $B_{context} = \{ \text{Handedness}, \text{HotZoneMap}_{9 \times 9}, \text{WhiffRate}_{fastball} \}$

$$S_t = [C_{game}, P_{state}, B_{context}]$$

### 1.2 Action Space ($A_t$)
íˆ¬ìˆ˜ê°€ ì œì–´ ê°€ëŠ¥í•œ ë³€ìˆ˜ë“¤ì…ë‹ˆë‹¤.
* **Pitch Type (Discrete):** $\{ \text{FF(4-Seam)}, \text{SL(Slider)}, \text{CH(Changeup)}, \text{CU(Curve)}, \dots \}$
* **Location (Continuous/Discrete Grid):** í™ˆ í”Œë ˆì´íŠ¸ ìƒì˜ ì¢Œí‘œ $(x, z)$. í•™ìŠµ ì•ˆì •ì„±ì„ ìœ„í•´ $5 \times 5$ ê·¸ë¦¬ë“œë¡œ ì´ì‚°í™”í•˜ê±°ë‚˜, ì—°ì† ê³µê°„ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤.

### 1.3 Reward Function ($R_t$)
ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ìœ¼ë¡œ, ì—ì´ì „íŠ¸ê°€ ìŠ¹ë¦¬(Run Expectancy ìµœì†Œí™”)ë¥¼ ì§€í–¥í•˜ë„ë¡ ì„¤ê³„í•©ë‹ˆë‹¤.

$$R_t = R_{outcome} + \lambda_1 R_{deception} - \lambda_2 R_{fatigue}$$

1.  **Outcome Reward ($R_{outcome}$):** **Delta Run Value (RE24)** ê¸°ë°˜.
    * Strike: $+0.05$ (ìƒí™©ì— ë”°ë¼ ê°€ë³€)
    * Ball: $-0.06$
    * Strikeout: $+0.25$
    * Home Run: $-1.40$
2.  **Deception Bonus ($R_{deception}$):** í”¼ì¹˜ í„°ë„ë§(Tunneling) íš¨ê³¼.
    * ì§ì „ íˆ¬êµ¬ì™€ ë¦´ë¦¬ìŠ¤ í¬ì¸íŠ¸ ë° ì´ˆë°˜ ê¶¤ì ì´ ìœ ì‚¬í• ìˆ˜ë¡ ë³´ìƒ ë¶€ì—¬.
3.  **Fatigue Penalty ($R_{fatigue}$):**
    * ìµœëŒ€ êµ¬ì† íˆ¬êµ¬ë¥¼ ì—°ì†ìœ¼ë¡œ í•  ê²½ìš° í˜ë„í‹° ë¶€ì—¬ (ìƒì²´ì—­í•™ì  ë³´í˜¸).

## 2. Batter Behavior Modeling (The World Model)
ê°•í™”í•™ìŠµ í™˜ê²½ì˜ í•µì‹¬ì¸ íƒ€ì ëª¨ë¸ $P(O_t | S_t, A_t)$ì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë©ë‹ˆë‹¤.

* **Swing Probability:**
    $$P(\text{Swing}) = \sigma(W \cdot \phi(S_t, A_t) + b)$$
    ($\sigma$: Sigmoid, $\phi$: Feature Vector derived from XGBoost)
* **Contact Quality:**
    ìŠ¤ìœ™ ì‹œ, `Launch Angle`ê³¼ `Exit Velocity`ëŠ” íƒ€ìì˜ ê³¼ê±° íƒ€êµ¬ ë°ì´í„° ë¶„í¬(KDE)ì™€ íˆ¬êµ¬ì˜ ë¬¼ë¦¬ì  íŠ¹ì„±(VAA, Spin)ì„ ì¡°ê±´ë¶€ í™•ë¥ ë¡œ ìƒ˜í”Œë§í•˜ì—¬ ê²°ì •í•©ë‹ˆë‹¤.

## 3. Training Strategy

### Phase 1: Behavior Cloning (BC)
Random Initialization ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, 2023ë…„ MLB ìƒìœ„ 10% íˆ¬ìˆ˜(ERA ê¸°ì¤€)ì˜ (State, Action) ìŒì„ ì§€ë„ í•™ìŠµí•©ë‹ˆë‹¤.
$$\mathcal{L}_{BC} = - \sum \log \pi_\theta(a_{expert} | s)$$

### Phase 2: Proximal Policy Optimization (PPO)
BCë¡œ ì´ˆê¸°í™”ëœ ì •ì±… $\pi_\theta$ë¥¼ ì‹œì‘ì ìœ¼ë¡œ í•˜ì—¬, PPOë¥¼ í†µí•´ ê¸°ëŒ€ ë³´ìƒ(Run Value ìµœì†Œí™”)ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
$$L^{CLIP}(\theta) = \hat{\mathbb{E}}_t [\min(r_t(\theta)\hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)\hat{A}_t)]$$

---
**References:**
- *Sidiger et al., "Optimizing Pitch Sequencing with Deep RL", MIT Sloan Sports Analytics Conference.*
- *Tango et al., "The Book: Playing the Percentages in Baseball".*